{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Logsignature example\n",
    "This notebook is based on the examples from the `torchcde` package by Kidger and Morrill which can be found at\n",
    "[https://github.com/patrick-kidger/torchcde](https://github.com/patrick-kidger/torchcde).\n",
    "Further information about the techniques described in this notebook can be found\n",
    "\n",
    "> Morrill, J., Salvi, C., Kidger, P., Foster, J. and Lyons, T., 2020.\n",
    "  Neural rough differential equations for long time series.\n",
    "  arXiv preprint arXiv:[2009.08295](https://arxiv.org/abs/2009.08295)\n",
    "\n",
    "> Morrill, J., Kidger, P., Yang, L. and Lyons, T., 2021.\n",
    "  Neural Controlled Differential Equations for Online Prediction Tasks.\n",
    "  arXiv preprint arXiv:[2106.11028](https://arxiv.org/abs/2106.11028).\n",
    "\n",
    "> Kidger, P., Foster, J., Li, X., Oberhauser, H. and Lyons, T., 2021.\n",
    "  Neural sdes as infinite-dimensional gans.\n",
    "  arXiv preprint arXiv:[2102.03657](https://arxiv.org/abs/2102.03657).\n",
    "\n",
    "In this notebook we code up a Neural CDE using the log-ode method for a long time series thus becoming a Neural RDE.\n",
    "We will only describe the differences from that example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set up the notebook\n",
    "\n",
    "\n",
    "### Install dependencies\n",
    "This notebook uses PyTorch along with"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchcde@ git+https://github.com/patrick-kidger/torchcde.git@4620b4b8bfb08416f4871c9e76510b69439ee916\r\n",
      "  Cloning https://github.com/patrick-kidger/torchcde.git (to revision 4620b4b8bfb08416f4871c9e76510b69439ee916) to /tmp/pip-install-sjadnydl/torchcde_37b73a691fa5457fb8fbb7e106454be4\r\n",
      "  Running command git clone -q https://github.com/patrick-kidger/torchcde.git /tmp/pip-install-sjadnydl/torchcde_37b73a691fa5457fb8fbb7e106454be4\r\n",
      "  Running command git rev-parse -q --verify 'sha^4620b4b8bfb08416f4871c9e76510b69439ee916'\r\n",
      "  Running command git fetch -q https://github.com/patrick-kidger/torchcde.git 4620b4b8bfb08416f4871c9e76510b69439ee916\r\n",
      "Requirement already satisfied: wheel in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (0.36.2)\r\n",
      "Requirement already satisfied: matplotlib in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (3.4.2)\r\n",
      "Requirement already satisfied: torch==1.9.0 in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (1.9.0)\r\n",
      "Requirement already satisfied: signatory in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (1.2.4.1.7.1)\r\n",
      "Collecting torchsde@ git+https://github.com/google-research/torchsde.git\r\n",
      "  Cloning https://github.com/google-research/torchsde.git to /tmp/pip-install-sjadnydl/torchsde_44060aa4901d47d4abe30cb2dad4b661\r\n",
      "  Running command git clone -q https://github.com/google-research/torchsde.git /tmp/pip-install-sjadnydl/torchsde_44060aa4901d47d4abe30cb2dad4b661\r\n",
      "  Installing build dependencies ... \u001B[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25l-\b \bdone\r\n",
      "\u001B[?25h    Preparing wheel metadata ... \u001B[?25l-\b \bdone\r\n",
      "\u001B[?25hRequirement already satisfied: torchdiffeq>=0.2.0 in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from torchcde@ git+https://github.com/patrick-kidger/torchcde.git@4620b4b8bfb08416f4871c9e76510b69439ee916->-r requirements.txt (line 4)) (0.2.2)\r\n",
      "Requirement already satisfied: numpy==1.19.* in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from torchsde@ git+https://github.com/google-research/torchsde.git->torchcde@ git+https://github.com/patrick-kidger/torchcde.git@4620b4b8bfb08416f4871c9e76510b69439ee916->-r requirements.txt (line 4)) (1.19.5)\r\n",
      "Requirement already satisfied: scipy==1.5.* in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from torchsde@ git+https://github.com/google-research/torchsde.git->torchcde@ git+https://github.com/patrick-kidger/torchcde.git@4620b4b8bfb08416f4871c9e76510b69439ee916->-r requirements.txt (line 4)) (1.5.4)\r\n",
      "Requirement already satisfied: trampoline>=0.1.2 in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from torchsde@ git+https://github.com/google-research/torchsde.git->torchcde@ git+https://github.com/patrick-kidger/torchcde.git@4620b4b8bfb08416f4871c9e76510b69439ee916->-r requirements.txt (line 4)) (0.1.2)\r\n",
      "Requirement already satisfied: boltons>=20.2.1 in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from torchsde@ git+https://github.com/google-research/torchsde.git->torchcde@ git+https://github.com/patrick-kidger/torchcde.git@4620b4b8bfb08416f4871c9e76510b69439ee916->-r requirements.txt (line 4)) (21.0.0)\r\n",
      "Requirement already satisfied: typing-extensions in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from torch==1.9.0->-r requirements.txt (line 3)) (3.10.0.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 2)) (1.3.1)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 2)) (8.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 2)) (0.10.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 2)) (2.4.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 2)) (2.8.1)\r\n",
      "Requirement already satisfied: six in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from cycler>=0.10->matplotlib->-r requirements.txt (line 2)) (1.16.0)\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torchcde"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use the `CDEFunc` and `NeuralCDE` classes, and the `get_data` function defined in the _time series classificiation_\n",
    "notebook."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class CDEFunc(torch.nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels):\n",
    "        ######################\n",
    "        # input_channels is the number of input channels in the data X. (Determined by the data.)\n",
    "        # hidden_channels is the number of channels for z_t. (Determined by you!)\n",
    "        ######################\n",
    "        super(CDEFunc, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(hidden_channels, 128)\n",
    "        self.linear2 = torch.nn.Linear(128, input_channels * hidden_channels)\n",
    "\n",
    "    ######################\n",
    "    # For most purposes the t argument can probably be ignored; unless you want your CDE to behave differently at\n",
    "    # different times, which would be unusual. But it's there if you need it!\n",
    "    ######################\n",
    "    def forward(self, t, z):\n",
    "        # z has shape (batch, hidden_channels)\n",
    "        z = self.linear1(z)\n",
    "        z = z.relu()\n",
    "        z = self.linear2(z)\n",
    "        ######################\n",
    "        # Easy-to-forget gotcha: Best results tend to be obtained by adding a final tanh nonlinearity.\n",
    "        ######################\n",
    "        z = z.tanh()\n",
    "        ######################\n",
    "        # Ignoring the batch dimension, the shape of the output tensor must be a matrix,\n",
    "        # because we need it to represent a linear map from R^input_channels to R^hidden_channels.\n",
    "        ######################\n",
    "        z = z.view(z.size(0), self.hidden_channels, self.input_channels)\n",
    "        return z\n",
    "\n",
    "\n",
    "class NeuralCDE(torch.nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, output_channels, interpolation=\"cubic\"):\n",
    "        super(NeuralCDE, self).__init__()\n",
    "\n",
    "        self.func = CDEFunc(input_channels, hidden_channels)\n",
    "        self.initial = torch.nn.Linear(input_channels, hidden_channels)\n",
    "        self.readout = torch.nn.Linear(hidden_channels, output_channels)\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def forward(self, coeffs):\n",
    "        if self.interpolation == 'cubic':\n",
    "            X = torchcde.NaturalCubicSpline(coeffs)\n",
    "        elif self.interpolation == 'linear':\n",
    "            X = torchcde.LinearInterpolation(coeffs)\n",
    "        else:\n",
    "            raise ValueError(\"Only 'linear' and 'cubic' interpolation methods are implemented.\")\n",
    "\n",
    "        ######################\n",
    "        # Easy to forget gotcha: Initial hidden state should be a function of the first observation.\n",
    "        ######################\n",
    "        X0 = X.evaluate(X.interval[0])\n",
    "        z0 = self.initial(X0)\n",
    "\n",
    "        ######################\n",
    "        # Actually solve the CDE.\n",
    "        ######################\n",
    "        z_T = torchcde.cdeint(X=X,\n",
    "                              z0=z0,\n",
    "                              func=self.func,\n",
    "                              t=X.interval)\n",
    "\n",
    "        ######################\n",
    "        # Both the initial value and the terminal value are returned from cdeint; extract just the terminal value,\n",
    "        # and then apply a linear map.\n",
    "        ######################\n",
    "        z_T = z_T[:, 1]\n",
    "        pred_y = self.readout(z_T)\n",
    "        return pred_y\n",
    "\n",
    "\n",
    "def get_data(num_timepoints=100):\n",
    "    t = torch.linspace(0., 4 * math.pi, num_timepoints)\n",
    "\n",
    "    start = torch.rand(128) * 2 * math.pi\n",
    "    x_pos = torch.cos(start.unsqueeze(1) + t.unsqueeze(0)) / (1 + 0.5 * t)\n",
    "    x_pos[:64] *= -1\n",
    "    y_pos = torch.sin(start.unsqueeze(1) + t.unsqueeze(0)) / (1 + 0.5 * t)\n",
    "    x_pos += 0.01 * torch.randn_like(x_pos)\n",
    "    y_pos += 0.01 * torch.randn_like(y_pos)\n",
    "    ######################\n",
    "    # Easy to forget gotcha: time should be included as a channel; Neural CDEs need to be explicitly told the\n",
    "    # rate at which time passes. Here, we have a regularly sampled dataset, so appending time is pretty simple.\n",
    "    ######################\n",
    "    X = torch.stack([t.unsqueeze(0).repeat(128, 1), x_pos, y_pos], dim=2)\n",
    "    y = torch.zeros(128)\n",
    "    y[:64] = 1\n",
    "\n",
    "    perm = torch.randperm(128)\n",
    "    X = X[perm]\n",
    "    y = y[perm]\n",
    "\n",
    "    ######################\n",
    "    # X is a tensor of observations, of shape (batch=128, sequence=100, channels=3)\n",
    "    # y is a tensor of labels, of shape (batch=128,), either 0 or 1 corresponding to anticlockwise or clockwise respectively.\n",
    "    ######################\n",
    "    return X, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can define a function that will train the model and evaluate the performance on our data set using logsignatures\n",
    "up to a specified depth."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def train_and_evaluate(train_X, train_y, test_X, test_y, depth, num_epochs, window_length):\n",
    "    # Time the training process\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Logsignature computation step\n",
    "    train_logsig = torchcde.logsig_windows(train_X, depth, window_length=window_length)\n",
    "    print(\"Logsignature shape: {}\".format(train_logsig.size()))\n",
    "\n",
    "    model = NeuralCDE(\n",
    "        input_channels=train_logsig.size(-1), hidden_channels=8, output_channels=1, interpolation=\"linear\"\n",
    "    )\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "    train_coeffs = torchcde.linear_interpolation_coeffs(train_logsig)\n",
    "\n",
    "    train_dataset = torch.utils.data.TensorDataset(train_coeffs, train_y)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32)\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in train_dataloader:\n",
    "            batch_coeffs, batch_y = batch\n",
    "            pred_y = model(batch_coeffs).squeeze(-1)\n",
    "            loss = torch.nn.functional.binary_cross_entropy_with_logits(pred_y, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        print(\"Epoch: {}   Training loss: {}\".format(epoch, loss.item()))\n",
    "\n",
    "    # Remember to compute the logsignatures of the test data too!\n",
    "    test_logsig = torchcde.logsig_windows(test_X, depth, window_length=window_length)\n",
    "    test_coeffs = torchcde.linear_interpolation_coeffs(test_logsig)\n",
    "    pred_y = model(test_coeffs).squeeze(-1)\n",
    "    binary_prediction = (torch.sigmoid(pred_y) > 0.5).to(test_y.dtype)\n",
    "    prediction_matches = (binary_prediction == test_y).to(test_y.dtype)\n",
    "    proportion_correct = prediction_matches.sum() / test_y.size(0)\n",
    "    print(\"Test Accuracy: {}\".format(proportion_correct))\n",
    "\n",
    "    # Total time\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    return proportion_correct, elapsed\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we load a high frequency version of the spiral data using in `torchcde.example`. Each sample contains 5000\n",
    "time points. This is too long to sensibly expect a Neural CDE to handle, training time will be very long and it\n",
    "will struggle to remember information from early on in the sequence."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "num_timepoints = 5000\n",
    "train_X, train_y = get_data(num_timepoints=num_timepoints)\n",
    "test_X, test_y = get_data(num_timepoints=num_timepoints)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We test the model over logsignature depths 1, 2, and 3, with a window length of 50. This reduces the effective\n",
    "length of the path to just 100. The only change is an application of `torchcde.logsig_windows`\n",
    "\n",
    "The raw signal has 3 input channels. Taking logsignatures of depths 1, 2, and 3 results in a path of logsignatures\n",
    "of dimension 3, 6, and 14 respectively. We see that higher logsignature depths contain more information about the\n",
    "path over the intervals, at a cost of increased numbers of channels."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for logsignature depth: 1\n",
      "Logsignature shape: torch.Size([128, 101, 3])\n",
      "Epoch: 0   Training loss: 2.5779426097869873\n",
      "Epoch: 1   Training loss: 0.9518626928329468\n",
      "Epoch: 2   Training loss: 0.6158618927001953\n",
      "Epoch: 3   Training loss: 0.678015410900116\n",
      "Epoch: 4   Training loss: 0.6150668263435364\n",
      "Epoch: 5   Training loss: 0.521719753742218\n",
      "Epoch: 6   Training loss: 0.36672350764274597\n",
      "Epoch: 7   Training loss: 0.47279104590415955\n",
      "Epoch: 8   Training loss: 0.4549952447414398\n",
      "Epoch: 9   Training loss: 0.28105735778808594\n",
      "Test Accuracy: 0.953125\n",
      "Running for logsignature depth: 2\n",
      "Logsignature shape: torch.Size([128, 101, 6])\n",
      "Epoch: 0   Training loss: 0.4106109142303467\n",
      "Epoch: 1   Training loss: 1.03876793384552\n",
      "Epoch: 2   Training loss: 0.7270088791847229\n",
      "Epoch: 3   Training loss: 0.8129279613494873\n",
      "Epoch: 4   Training loss: 0.63377445936203\n",
      "Epoch: 5   Training loss: 0.554548978805542\n",
      "Epoch: 6   Training loss: 0.3670040965080261\n",
      "Epoch: 7   Training loss: 0.24859601259231567\n",
      "Epoch: 8   Training loss: 0.21137933433055878\n",
      "Epoch: 9   Training loss: 0.13586123287677765\n",
      "Test Accuracy: 1.0\n",
      "Running for logsignature depth: 3\n",
      "Logsignature shape: torch.Size([128, 101, 14])\n",
      "Epoch: 0   Training loss: 1.8173232078552246\n",
      "Epoch: 1   Training loss: 0.6811091899871826\n",
      "Epoch: 2   Training loss: 0.6513993740081787\n",
      "Epoch: 3   Training loss: 0.8890698552131653\n",
      "Epoch: 4   Training loss: 0.7527800798416138\n",
      "Epoch: 5   Training loss: 0.6541873812675476\n",
      "Epoch: 6   Training loss: 0.4622846245765686\n",
      "Epoch: 7   Training loss: 0.4191521406173706\n",
      "Epoch: 8   Training loss: 0.3354116380214691\n",
      "Epoch: 9   Training loss: 0.24805358052253723\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "depths = [1, 2, 3]\n",
    "window_length = 50\n",
    "accuracies = []\n",
    "training_times = []\n",
    "for depth in depths:\n",
    "    print(f'Running for logsignature depth: {depth}')\n",
    "    acc, elapsed = train_and_evaluate(\n",
    "        train_X, train_y, test_X, test_y, depth, NUM_EPOCHS, window_length\n",
    "    )\n",
    "    training_times.append(elapsed)\n",
    "    accuracies.append(acc)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, log the results to the console for a comparison"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results\n",
      "Depth: 1\n",
      "\tAccuracy on test set: 95.3%\n",
      "\tTime per epoch: 3.8s\n",
      "Depth: 2\n",
      "\tAccuracy on test set: 100.0%\n",
      "\tTime per epoch: 3.5s\n",
      "Depth: 3\n",
      "\tAccuracy on test set: 100.0%\n",
      "\tTime per epoch: 5.7s\n"
     ]
    }
   ],
   "source": [
    "print(\"Final results\")\n",
    "for acc, elapsed, depth in zip(accuracies, training_times, depths):\n",
    "    print(\n",
    "        f\"Depth: {depth}\\n\\tAccuracy on test set: {acc*100:.1f}%\\n\\tTime per epoch: {elapsed/NUM_EPOCHS:.1f}s\"\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}