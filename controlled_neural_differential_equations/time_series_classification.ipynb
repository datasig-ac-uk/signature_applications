{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Controlled Neural Differential Equations - Time Series Classification\n",
    "This notebook is based on the examples from the `torchcde` package by Kidger and Morrill which can be found at\n",
    "[https://github.com/patrick-kidger/torchcde](https://github.com/patrick-kidger/torchcde).\n",
    "Further information about the techniques described in this notebook can be found\n",
    "\n",
    "> Kidger, P., Morrill, J., Foster, J. and Lyons, T., 2020.\n",
    " Neural controlled differential equations for irregular time series.\n",
    " arXiv preprint arXiv:[2005.08926](https://arxiv.org/abs/2005.08926).\n",
    "\n",
    "> Morrill, J., Kidger, P., Yang, L. and Lyons, T., 2021.\n",
    " Neural Controlled Differential Equations for Online Prediction Tasks.\n",
    " arXiv preprint arXiv:[2106.11028](https://arxiv.org/abs/2106.11028).\n",
    "\n",
    "> Kidger, P., Foster, J., Li, X., Oberhauser, H. and Lyons, T., 2021.\n",
    " Neural sdes as infinite-dimensional gans.\n",
    " arXiv preprint arXiv:[2102.03657](https://arxiv.org/abs/2102.03657).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set up the notebook\n",
    "\n",
    "### Install dependencies\n",
    "This notebook requires PyTorch and the torchcde package."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchcde@ git+https://github.com/patrick-kidger/torchcde.git@4620b4b8bfb08416f4871c9e76510b69439ee916\r\n",
      "  Cloning https://github.com/patrick-kidger/torchcde.git (to revision 4620b4b8bfb08416f4871c9e76510b69439ee916) to /tmp/pip-install-y33cw0nj/torchcde_c55209073b2243b28220a5e9bde64024\r\n",
      "  Running command git clone -q https://github.com/patrick-kidger/torchcde.git /tmp/pip-install-y33cw0nj/torchcde_c55209073b2243b28220a5e9bde64024\r\n",
      "  Running command git rev-parse -q --verify 'sha^4620b4b8bfb08416f4871c9e76510b69439ee916'\r\n",
      "  Running command git fetch -q https://github.com/patrick-kidger/torchcde.git 4620b4b8bfb08416f4871c9e76510b69439ee916\r\n",
      "Requirement already satisfied: matplotlib in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (3.4.2)\r\n",
      "Requirement already satisfied: torch==1.9.0 in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (1.9.0)\r\n",
      "Collecting torchsde@ git+https://github.com/google-research/torchsde.git\r\n",
      "  Cloning https://github.com/google-research/torchsde.git to /tmp/pip-install-y33cw0nj/torchsde_9e2c2cbb9e4d429a9459ac51d0967926\r\n",
      "  Running command git clone -q https://github.com/google-research/torchsde.git /tmp/pip-install-y33cw0nj/torchsde_9e2c2cbb9e4d429a9459ac51d0967926\r\n",
      "  Installing build dependencies ... \u001B[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25l-\b \bdone\r\n",
      "\u001B[?25h    Preparing wheel metadata ... \u001B[?25l-\b \bdone\r\n",
      "\u001B[?25hRequirement already satisfied: torchdiffeq>=0.2.0 in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from torchcde@ git+https://github.com/patrick-kidger/torchcde.git@4620b4b8bfb08416f4871c9e76510b69439ee916->-r requirements.txt (line 3)) (0.2.2)\r\n",
      "Requirement already satisfied: boltons>=20.2.1 in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from torchsde@ git+https://github.com/google-research/torchsde.git->torchcde@ git+https://github.com/patrick-kidger/torchcde.git@4620b4b8bfb08416f4871c9e76510b69439ee916->-r requirements.txt (line 3)) (21.0.0)\r\n",
      "Requirement already satisfied: scipy==1.5.* in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from torchsde@ git+https://github.com/google-research/torchsde.git->torchcde@ git+https://github.com/patrick-kidger/torchcde.git@4620b4b8bfb08416f4871c9e76510b69439ee916->-r requirements.txt (line 3)) (1.5.4)\r\n",
      "Requirement already satisfied: numpy==1.19.* in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from torchsde@ git+https://github.com/google-research/torchsde.git->torchcde@ git+https://github.com/patrick-kidger/torchcde.git@4620b4b8bfb08416f4871c9e76510b69439ee916->-r requirements.txt (line 3)) (1.19.5)\r\n",
      "Requirement already satisfied: trampoline>=0.1.2 in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from torchsde@ git+https://github.com/google-research/torchsde.git->torchcde@ git+https://github.com/patrick-kidger/torchcde.git@4620b4b8bfb08416f4871c9e76510b69439ee916->-r requirements.txt (line 3)) (0.1.2)\r\n",
      "Requirement already satisfied: typing-extensions in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from torch==1.9.0->-r requirements.txt (line 2)) (3.10.0.0)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 1)) (8.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 1)) (0.10.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 1)) (2.8.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 1)) (2.4.7)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 1)) (1.3.1)\r\n",
      "Requirement already satisfied: six in /home/sam/PycharmProjects/signature_applications/venv/lib/python3.9/site-packages (from cycler>=0.10->matplotlib->-r requirements.txt (line 1)) (1.16.0)\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import the necessary packages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchcde\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A CDE model looks like\n",
    "\n",
    "$$z_t = z_0 + \\int_0^t f_\\theta(z_s) dX_s$$\n",
    "\n",
    "Where $X$ is your data and $f_\\theta$ is a neural network. So the first thing we need to do is define such an $f_\\theta$.\n",
    "That's what this CDEFunc class does.\n",
    "Here we've built a small single-hidden-layer neural network, whose hidden layer is of width 128."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class CDEFunc(torch.nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels):\n",
    "        ######################\n",
    "        # input_channels is the number of input channels in the data X. (Determined by the data.)\n",
    "        # hidden_channels is the number of channels for z_t. (Determined by you!)\n",
    "        ######################\n",
    "        super(CDEFunc, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(hidden_channels, 128)\n",
    "        self.linear2 = torch.nn.Linear(128, input_channels * hidden_channels)\n",
    "\n",
    "    ######################\n",
    "    # For most purposes the t argument can probably be ignored; unless you want your CDE to behave differently at\n",
    "    # different times, which would be unusual. But it's there if you need it!\n",
    "    ######################\n",
    "    def forward(self, t, z):\n",
    "        # z has shape (batch, hidden_channels)\n",
    "        z = self.linear1(z)\n",
    "        z = z.relu()\n",
    "        z = self.linear2(z)\n",
    "        ######################\n",
    "        # Easy-to-forget gotcha: Best results tend to be obtained by adding a final tanh nonlinearity.\n",
    "        ######################\n",
    "        z = z.tanh()\n",
    "        ######################\n",
    "        # Ignoring the batch dimension, the shape of the output tensor must be a matrix,\n",
    "        # because we need it to represent a linear map from R^input_channels to R^hidden_channels.\n",
    "        ######################\n",
    "        z = z.view(z.size(0), self.hidden_channels, self.input_channels)\n",
    "        return z"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we need to package CDEFunc up into a model that computes the integral."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class NeuralCDE(torch.nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, output_channels, interpolation=\"cubic\"):\n",
    "        super(NeuralCDE, self).__init__()\n",
    "\n",
    "        self.func = CDEFunc(input_channels, hidden_channels)\n",
    "        self.initial = torch.nn.Linear(input_channels, hidden_channels)\n",
    "        self.readout = torch.nn.Linear(hidden_channels, output_channels)\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def forward(self, coeffs):\n",
    "        if self.interpolation == 'cubic':\n",
    "            X = torchcde.NaturalCubicSpline(coeffs)\n",
    "        elif self.interpolation == 'linear':\n",
    "            X = torchcde.LinearInterpolation(coeffs)\n",
    "        else:\n",
    "            raise ValueError(\"Only 'linear' and 'cubic' interpolation methods are implemented.\")\n",
    "\n",
    "        ######################\n",
    "        # Easy to forget gotcha: Initial hidden state should be a function of the first observation.\n",
    "        ######################\n",
    "        X0 = X.evaluate(X.interval[0])\n",
    "        z0 = self.initial(X0)\n",
    "\n",
    "        ######################\n",
    "        # Actually solve the CDE.\n",
    "        ######################\n",
    "        z_T = torchcde.cdeint(X=X,\n",
    "                              z0=z0,\n",
    "                              func=self.func,\n",
    "                              t=X.interval)\n",
    "\n",
    "        ######################\n",
    "        # Both the initial value and the terminal value are returned from cdeint; extract just the terminal value,\n",
    "        # and then apply a linear map.\n",
    "        ######################\n",
    "        z_T = z_T[:, 1]\n",
    "        pred_y = self.readout(z_T)\n",
    "        return pred_y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we need some data.\n",
    "Here we have a simple example which generates some spirals, some going clockwise, some going anticlockwise."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_data(num_timepoints=100):\n",
    "    t = torch.linspace(0., 4 * math.pi, num_timepoints)\n",
    "\n",
    "    start = torch.rand(128) * 2 * math.pi\n",
    "    x_pos = torch.cos(start.unsqueeze(1) + t.unsqueeze(0)) / (1 + 0.5 * t)\n",
    "    x_pos[:64] *= -1\n",
    "    y_pos = torch.sin(start.unsqueeze(1) + t.unsqueeze(0)) / (1 + 0.5 * t)\n",
    "    x_pos += 0.01 * torch.randn_like(x_pos)\n",
    "    y_pos += 0.01 * torch.randn_like(y_pos)\n",
    "    ######################\n",
    "    # Easy to forget gotcha: time should be included as a channel; Neural CDEs need to be explicitly told the\n",
    "    # rate at which time passes. Here, we have a regularly sampled dataset, so appending time is pretty simple.\n",
    "    ######################\n",
    "    X = torch.stack([t.unsqueeze(0).repeat(128, 1), x_pos, y_pos], dim=2)\n",
    "    y = torch.zeros(128)\n",
    "    y[:64] = 1\n",
    "\n",
    "    perm = torch.randperm(128)\n",
    "    X = X[perm]\n",
    "    y = y[perm]\n",
    "\n",
    "    ######################\n",
    "    # X is a tensor of observations, of shape (batch=128, sequence=100, channels=3)\n",
    "    # y is a tensor of labels, of shape (batch=128,), either 0 or 1 corresponding to anticlockwise or clockwise respectively.\n",
    "    ######################\n",
    "    return X, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 30"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "train_X, train_y = get_data()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, tight_layout=True)\n",
    "idx, = np.where(train_y == 0)\n",
    "ax1.plot(train_X[idx[0], :, 1], train_X[idx[0], :, 2])\n",
    "ax1.set_title(\"Anticlockwise spiral\")\n",
    "ax1.set_xlabel(\"x\")\n",
    "ax1.set_ylabel(\"y\")\n",
    "\n",
    "idx, = np.where(train_y == 1)\n",
    "ax2.plot(train_X[idx[0], :, 1], train_X[idx[0], :, 2])\n",
    "ax2.set_title(\"Clockwise spiral\")\n",
    "ax2.set_xlabel(\"x\")\n",
    "ax2.set_ylabel(\"y\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "input_channels=3 because we have both the horizontal and vertical position of a point in the spiral, and time.\n",
    "hidden_channels=8 is the number of hidden channels for the evolving z_t, which we get to choose.\n",
    "output_channels=1 because we're doing binary classification."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "model = NeuralCDE(input_channels=3, hidden_channels=8, output_channels=1)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we turn our dataset into a continuous path. We do this here via natural cubic spline interpolation.\n",
    "The resulting `train_coeffs` is a tensor describing the path.\n",
    "For most problems, it's probably easiest to save this tensor and treat it as the dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "train_coeffs = torchcde.natural_cubic_coeffs(train_X)\n",
    "train_dataset = torch.utils.data.TensorDataset(train_coeffs, train_y)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0   Training loss: 0.591900110244751\n",
      "Epoch:  1   Training loss: 0.5691879987716675\n",
      "Epoch:  2   Training loss: 0.4391317367553711\n",
      "Epoch:  3   Training loss: 0.3183804154396057\n",
      "Epoch:  4   Training loss: 0.12590204179286957\n",
      "Epoch:  5   Training loss: 0.05028655752539635\n",
      "Epoch:  6   Training loss: 0.019360331818461418\n",
      "Epoch:  7   Training loss: 0.009352361783385277\n",
      "Epoch:  8   Training loss: 0.005007205996662378\n",
      "Epoch:  9   Training loss: 0.0029659783467650414\n",
      "Epoch: 10   Training loss: 0.0019759959541261196\n",
      "Epoch: 11   Training loss: 0.0014610663056373596\n",
      "Epoch: 12   Training loss: 0.001173303578980267\n",
      "Epoch: 13   Training loss: 0.0010014527942985296\n",
      "Epoch: 14   Training loss: 0.000883798929862678\n",
      "Epoch: 15   Training loss: 0.0008047460578382015\n",
      "Epoch: 16   Training loss: 0.000749182072468102\n",
      "Epoch: 17   Training loss: 0.0007003145292401314\n",
      "Epoch: 18   Training loss: 0.0006656608311459422\n",
      "Epoch: 19   Training loss: 0.0006364437285810709\n",
      "Epoch: 20   Training loss: 0.0006101467297412455\n",
      "Epoch: 21   Training loss: 0.0005900644464418292\n",
      "Epoch: 22   Training loss: 0.0005692458944395185\n",
      "Epoch: 23   Training loss: 0.0005545230815187097\n",
      "Epoch: 24   Training loss: 0.000538300140760839\n",
      "Epoch: 25   Training loss: 0.0005219880840741098\n",
      "Epoch: 26   Training loss: 0.0005088428151793778\n",
      "Epoch: 27   Training loss: 0.0004954450996592641\n",
      "Epoch: 28   Training loss: 0.00048229232197627425\n",
      "Epoch: 29   Training loss: 0.0004706286999862641\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    for batch in train_dataloader:\n",
    "        batch_coeffs, batch_y = batch\n",
    "        pred_y = model(batch_coeffs).squeeze(-1)\n",
    "        loss = torch.nn.functional.binary_cross_entropy_with_logits(pred_y, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print('Epoch: {:2d}   Training loss: {}'.format(epoch, loss.item()))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_X, test_y = get_data()\n",
    "\n",
    "\n",
    "test_coeffs = torchcde.natural_cubic_coeffs(test_X)\n",
    "pred_y = model(test_coeffs).squeeze(-1)\n",
    "binary_prediction = (torch.sigmoid(pred_y) > 0.5).to(test_y.dtype)\n",
    "prediction_matches = (binary_prediction == test_y).to(test_y.dtype)\n",
    "proportion_correct = prediction_matches.sum() / test_y.size(0)\n",
    "print('Test Accuracy: {}'.format(proportion_correct))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}